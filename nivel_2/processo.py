#!/usr/bin/env python3
"""
N√≠vel 2 - M√≥dulo de Processo PROJUDI API v4
Respons√°vel por extrair dados detalhados de processos
"""

import asyncio
import re
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from datetime import datetime

from playwright.async_api import Page, TimeoutError as PlaywrightTimeoutError
from bs4 import BeautifulSoup
from loguru import logger

from config import settings
from core.session_manager import Session
from nivel_1.busca import ProcessoEncontrado

@dataclass
class Movimentacao:
    """Representa uma movimenta√ß√£o do processo"""
    numero: int
    tipo: str
    descricao: str
    data: str
    usuario: str
    tem_anexo: bool
    id_movimentacao: str
    numero_processo: str = ""  # N√∫mero do processo ao qual pertence
    codigo_anexo: str = ""
    html_completo: str = ""

@dataclass
class ParteEnvolvida:
    """Representa uma parte envolvida no processo"""
    nome: str
    tipo: str  # Polo Ativo, Polo Passivo, etc.
    documento: str = ""  # CPF/CNPJ
    endereco: str = ""
    telefone: str = ""
    email: str = ""
    advogado: str = ""
    oab: str = ""

@dataclass
class DadosProcesso:
    """Dados completos de um processo"""
    numero: str
    classe: str
    assunto: str
    situacao: str = ""
    data_autuacao: str = ""
    data_distribuicao: str = ""
    valor_causa: str = ""
    orgao_julgador: str = ""
    id_acesso: str = ""  # ID de acesso do projeto localizado na p√°gina inicial
    movimentacoes: List[Movimentacao] = None
    partes_polo_ativo: List[ParteEnvolvida] = None
    partes_polo_passivo: List[ParteEnvolvida] = None
    outras_partes: List[ParteEnvolvida] = None
    
    def __post_init__(self):
        if self.movimentacoes is None:
            self.movimentacoes = []
        if self.partes_polo_ativo is None:
            self.partes_polo_ativo = []
        if self.partes_polo_passivo is None:
            self.partes_polo_passivo = []
        if self.outras_partes is None:
            self.outras_partes = []

class ProcessoManager:
    """Gerenciador de extra√ß√£o de dados de processos"""
    
    def __init__(self):
        self.base_url = settings.projudi_base_url
    
    async def navegar_para_processo(self, session: Session, id_processo: str) -> bool:
        """Navega para um processo espec√≠fico (m√©todo p√∫blico)"""
        try:
            # Criar um ProcessoEncontrado tempor√°rio para compatibilidade
            from nivel_1.busca import ProcessoEncontrado
            processo_temp = ProcessoEncontrado(
                numero="Processo",
                classe="",
                assunto="",
                id_processo=id_processo,
                indice=1
            )
            
            return await self.acessar_processo(session, processo_temp)
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao navegar para processo: {e}")
            return False
    
    async def acessar_processo(self, session: Session, processo: ProcessoEncontrado) -> bool:
        """Acessa um processo espec√≠fico"""
        try:
            logger.info(f"üìÑ Acessando processo {processo.numero} (ID: {processo.id_processo})")
            
            # Se j√° estamos na p√°gina do processo (busca direta), n√£o precisa clicar
            if processo.id_processo == "processo_direto":
                logger.info("‚ÑπÔ∏è J√° estamos na p√°gina do processo")
                return True
            
            # Estrat√©gia 1: Encontrar o processo correto na tabela pelo n√∫mero
            try:
                # Aguardar a tabela carregar - timeout reduzido
                await session.page.wait_for_selector('table#Tabela', timeout=15000)
                
                # Procurar especificamente nas linhas do tbody
                linhas = await session.page.query_selector_all('table#Tabela tbody tr')
                logger.info(f"üîç Analisando {len(linhas)} linhas da tabela")
                
                for i, linha in enumerate(linhas):
                    try:
                        colunas = await linha.query_selector_all('td')
                        if len(colunas) >= 6:
                            numero_na_linha = await colunas[2].inner_text()  # TD3 tem o n√∫mero
                            numero_limpo = numero_na_linha.strip()
                            
                            logger.debug(f"  Linha {i+1}: {numero_limpo}")
                            
                            if numero_limpo == processo.numero:
                                # Encontrou a linha correta! Buscar bot√£o na coluna 6 (TD6)
                                btn_editar = await colunas[5].query_selector('button[name="formLocalizarimgEditar"]')
                                if btn_editar:
                                    logger.info(f"üéØ Processo encontrado na linha {i+1}, clicando no bot√£o...")
                                    await btn_editar.click()
                                    await session.page.wait_for_load_state('networkidle', timeout=15000)
                                    logger.info(f"‚úÖ Processo {processo.numero} acessado via busca na tabela")
                                    return True
                                else:
                                    logger.warning(f"‚ö†Ô∏è Linha encontrada mas bot√£o n√£o localizado na coluna 6")
                    except Exception as e:
                        logger.debug(f"‚ö†Ô∏è Erro ao processar linha {i+1}: {e}")
                        continue
                
                logger.warning(f"‚ö†Ô∏è Processo {processo.numero} n√£o encontrado na tabela")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro na estrat√©gia 1: {e}")
            
            # Estrat√©gia 2: Tentar JavaScript para clicar no bot√£o correto por √≠ndice
            if processo.indice:
                script = f"""
                () => {{
                    const botoes = document.querySelectorAll('button[name="formLocalizarimgEditar"]');
                    if (botoes.length >= {processo.indice}) {{
                        botoes[{processo.indice - 1}].click();
                        return true;
                    }}
                    return false;
                }}
                """
                resultado = await session.page.evaluate(script)
                if resultado:
                    await session.page.wait_for_load_state('networkidle', timeout=15000)
                    logger.info("‚úÖ Processo acessado via JavaScript")
                    return True
            
            # Estrat√©gia 2: Procurar por bot√£o espec√≠fico com ID do processo
            if processo.id_processo:
                btn_selector = f'button[onclick*="{processo.id_processo}"], input[onclick*="{processo.id_processo}"]'
                btn_editar = await session.page.query_selector(btn_selector)
                
                if btn_editar:
                    await btn_editar.click()
                    await session.page.wait_for_load_state('networkidle', timeout=15000)
                    logger.info("‚úÖ Processo acessado via seletor espec√≠fico")
                    return True
            
            # Estrat√©gia 3: Fallback - primeiro bot√£o editar dispon√≠vel
            btn_editar = await session.page.query_selector('button[name="formLocalizarimgEditar"]')
            if btn_editar:
                await btn_editar.click()
                await session.page.wait_for_load_state('networkidle', timeout=15000)
                logger.info("‚úÖ Processo acessado via fallback")
                return True
            
            logger.error("‚ùå N√£o foi poss√≠vel encontrar bot√£o para acessar o processo")
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao acessar processo: {e}")
            return False
    
    async def extrair_dados_basicos(self, session: Session) -> Optional[DadosProcesso]:
        """Extrai apenas dados b√°sicos do processo da p√°gina atual"""
        try:
            dados_basicos = await self._extrair_dados_basicos(session.page)
            
            # Extrair n√∫mero do processo da p√°gina atual
            content = await session.page.content()
            numero_match = re.search(r'(\d{7}-\d{2}\.\d{4}\.\d\.\d{2}\.\d{4})', content)
            numero = numero_match.group(1) if numero_match else "Processo"
            
            return DadosProcesso(
                numero=numero,
                classe=dados_basicos.get('classe', ''),
                assunto=dados_basicos.get('assunto', ''),
                situacao=dados_basicos.get('situacao', ''),
                data_autuacao=dados_basicos.get('data_autuacao', ''),
                data_distribuicao=dados_basicos.get('data_distribuicao', ''),
                valor_causa=dados_basicos.get('valor_causa', ''),
                orgao_julgador=dados_basicos.get('orgao_julgador', ''),
                id_acesso=dados_basicos.get('id_acesso', '')
            )
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao extrair dados b√°sicos: {e}")
            return None
    
    async def extrair_movimentacoes(self, session: Session, limite: Optional[int] = None) -> List[Movimentacao]:
        """Extrai movimenta√ß√µes do processo (m√©todo p√∫blico)"""
        return await self._extrair_movimentacoes(session, limite)
    
    async def extrair_partes_envolvidas(self, session: Session) -> Dict[str, List[ParteEnvolvida]]:
        """Extrai partes envolvidas do processo (m√©todo p√∫blico)"""
        return await self._extrair_partes_envolvidas(session)
    
    async def buscar_processo_especifico(self, session: Session, numero_processo: str) -> Optional[DadosProcesso]:
        """Busca um processo espec√≠fico diretamente no n√≠vel 2 (contorna n√≠vel 1)"""
        try:
            logger.info(f"üîç Buscando processo espec√≠fico: {numero_processo}")
            
            # Fazer login se necess√°rio
            from nivel_1.busca import LoginManager
            if not await LoginManager.fazer_login(session):
                logger.error("‚ùå Falha no login para busca de processo espec√≠fico")
                return None
            
            # Navegar para p√°gina de busca
            busca_url = f"{self.base_url}/BuscaProcesso"
            await session.page.goto(busca_url, timeout=15000)
            await session.page.wait_for_load_state('networkidle', timeout=15000)
            
            # Preencher n√∫mero do processo
            await session.page.fill('input[name="ProcessoNumero"]', '')
            await session.page.fill('input[name="ProcessoNumero"]', numero_processo)
            
            # Clicar em buscar
            await session.page.click('input[value="Buscar"]')
            await session.page.wait_for_load_state('networkidle', timeout=15000)
            
            # Verificar se foi redirecionado diretamente para o processo
            content = await session.page.content()
            if "corpo_dados_processo" in content:
                logger.info(f"‚úÖ Processo {numero_processo} encontrado diretamente")
                
                # Criar objeto ProcessoEncontrado tempor√°rio
                from nivel_1.busca import ProcessoEncontrado
                processo_temp = ProcessoEncontrado(
                    numero=numero_processo,
                    classe="Processo espec√≠fico",
                    assunto="Busca direta",
                    id_processo="processo_direto",
                    indice=1
                )
                
                # Extrair dados completos
                return await self.extrair_dados_processo(session, processo_temp)
            else:
                logger.warning(f"‚ö†Ô∏è Processo {numero_processo} n√£o encontrado ou n√£o acess√≠vel")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao buscar processo espec√≠fico {numero_processo}: {e}")
            return None
    
    async def extrair_dados_processo(self, session: Session, processo: ProcessoEncontrado, limite_movimentacoes: Optional[int] = None) -> DadosProcesso:
        """Extrai dados completos de um processo"""
        try:
            logger.info(f"üìã Extraindo dados do processo {processo.numero}")
            
            # Extrair dados b√°sicos da p√°gina atual
            dados_basicos = await self._extrair_dados_basicos(session.page)
            
            # Extrair movimenta√ß√µes
            movimentacoes = await self._extrair_movimentacoes(session, limite_movimentacoes)
            
            # Adicionar n√∫mero do processo a cada movimenta√ß√£o
            for mov in movimentacoes:
                mov.numero_processo = processo.numero
            
            # Extrair partes envolvidas
            partes = await self._extrair_partes_envolvidas(session)
            
            # Criar objeto com dados completos
            dados = DadosProcesso(
                numero=processo.numero,
                classe=processo.classe,
                assunto=processo.assunto,
                situacao=dados_basicos.get('situacao', ''),
                data_autuacao=dados_basicos.get('data_autuacao', ''),
                data_distribuicao=dados_basicos.get('data_distribuicao', ''),
                valor_causa=dados_basicos.get('valor_causa', ''),
                orgao_julgador=dados_basicos.get('orgao_julgador', ''),
                id_acesso=dados_basicos.get('id_acesso', ''),
                movimentacoes=movimentacoes,
                partes_polo_ativo=partes.get('polo_ativo', []),
                partes_polo_passivo=partes.get('polo_passivo', []),
                outras_partes=partes.get('outros', [])
            )
            
            logger.info(f"‚úÖ Dados extra√≠dos: {len(movimentacoes)} movimenta√ß√µes, {len(dados.partes_polo_ativo + dados.partes_polo_passivo + dados.outras_partes)} partes")
            return dados
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao extrair dados do processo: {e}")
            # Retornar dados b√°sicos mesmo em caso de erro
            return DadosProcesso(
                numero=processo.numero,
                classe=processo.classe,
                assunto=processo.assunto
            )
    
    async def _extrair_dados_basicos(self, page: Page) -> Dict[str, str]:
        """Extrai dados b√°sicos do processo da p√°gina atual"""
        try:
            dados = {}
            content = await page.content()
            soup = BeautifulSoup(content, 'html.parser')
            
            # Extrair dados usando regex e BeautifulSoup
            texto_pagina = soup.get_text()
            
            # ID de acesso do projeto (span com id="span_proc_numero")
            try:
                span_proc_numero = soup.find('span', {'id': 'span_proc_numero'})
                if span_proc_numero:
                    id_acesso = span_proc_numero.get_text(strip=True)
                    if id_acesso:
                        dados['id_acesso'] = id_acesso
                        logger.debug(f"üÜî ID de acesso extra√≠do: {id_acesso}")
                else:
                    # Fallback: tentar encontrar por XPath via regex no HTML
                    xpath_match = re.search(r'<span[^>]*id="span_proc_numero"[^>]*class="bold"[^>]*>\s*([^<]+)\s*</span>', content, re.I | re.S)
                    if xpath_match:
                        id_acesso = xpath_match.group(1).strip()
                        dados['id_acesso'] = id_acesso
                        logger.debug(f"üÜî ID de acesso extra√≠do via fallback: {id_acesso}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro ao extrair ID de acesso: {e}")
            
            # Data de autua√ß√£o
            match = re.search(r'Data\s+de\s+Autua√ß√£o[:\s]+(\d{2}/\d{2}/\d{4})', texto_pagina, re.I)
            if match:
                dados['data_autuacao'] = match.group(1)
            
            # Data de distribui√ß√£o
            match = re.search(r'Data\s+de\s+Distribui√ß√£o[:\s]+(\d{2}/\d{2}/\d{4})', texto_pagina, re.I)
            if match:
                dados['data_distribuicao'] = match.group(1)
            
            # Valor da causa
            match = re.search(r'Valor\s+da\s+Causa[:\s]+([R$\s\d.,]+)', texto_pagina, re.I)
            if match:
                dados['valor_causa'] = match.group(1).strip()
            
            # Situa√ß√£o
            match = re.search(r'Situa√ß√£o[:\s]+([^\n\r]+)', texto_pagina, re.I)
            if match:
                dados['situacao'] = match.group(1).strip()
            
            # √ìrg√£o julgador
            match = re.search(r'√ìrg√£o\s+Julgador[:\s]+([^\n\r]+)', texto_pagina, re.I)
            if match:
                dados['orgao_julgador'] = match.group(1).strip()
            
            return dados
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao extrair dados b√°sicos: {e}")
            return {}
    
    async def _extrair_movimentacoes(self, session: Session, limite: Optional[int] = None) -> List[Movimentacao]:
        """Extrai movimenta√ß√µes navegando para p√°gina de arquivos (baseado na vers√£o PLUS)"""
        try:
            logger.info("üìã Extraindo movimenta√ß√µes - navegando para p√°gina de arquivos...")
            
            movimentacoes = []
            
            # ESTRAT√âGIA PRINCIPAL: Tentar extrair da p√°gina atual primeiro (mais eficiente)
            logger.info("üîç Tentando extrair movimenta√ß√µes da p√°gina atual...")
            
            # Verificar se j√° tem TabelaArquivos na p√°gina atual
            if await session.page.query_selector('table#TabelaArquivos'):
                logger.info("üîç TabelaArquivos encontrada na p√°gina atual")
                movimentacoes = await self._extrair_movimentacoes_tabela_arquivos_inteligente(session.page)
                
            # Se n√£o conseguiu, tentar navegar para p√°gina de arquivos
            if not movimentacoes:
                logger.info("üîç Navegando para p√°gina de navega√ß√£o de arquivos...")
                navegacao_url = f"{self.base_url}/BuscaProcesso?PaginaAtual=9&PassoBusca=4"
                
                try:
                    await session.page.goto(navegacao_url, timeout=30000)
                    await session.page.wait_for_load_state('networkidle', timeout=30000)
                    logger.info("‚úÖ P√°gina de navega√ß√£o carregada")
                    
                    # Verificar se chegou na p√°gina correta (estrutura HTML ou tabela)
                    content = await session.page.content()
                    if "menuNavegacao" in content and "Movimenta√ß√µes Processo" in content:
                        logger.info("üîç P√°gina de navega√ß√£o HTML encontrada - extraindo movimenta√ß√µes...")
                        movimentacoes = await self._extrair_movimentacoes_navegacao_html(session.page)
                    elif await session.page.query_selector('table#TabelaArquivos'):
                        logger.info("üîç TabelaArquivos encontrada - extraindo movimenta√ß√µes...")
                        movimentacoes = await self._extrair_movimentacoes_tabela_arquivos_inteligente(session.page)
                    else:
                        logger.warning("‚ö†Ô∏è Nenhuma estrutura de movimenta√ß√µes encontrada na p√°gina de navega√ß√£o")
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao navegar para p√°gina de arquivos: {e}")
            
            # FALLBACK: Se n√£o conseguiu pela navega√ß√£o, tentar estrat√©gias alternativas
            if not movimentacoes:
                logger.info("üîç Tentando estrat√©gias de fallback...")
                
                # Verificar se j√° tem TabelaArquivos na p√°gina atual
                if await session.page.query_selector('table#TabelaArquivos'):
                    logger.info("üîç TabelaArquivos encontrada na p√°gina atual")
                    movimentacoes = await self._extrair_movimentacoes_tabela_arquivos_inteligente(session.page)
                
                            # Se ainda n√£o tem, tentar p√°gina principal com Playwright
            if not movimentacoes:
                logger.info("üîç Tentando p√°gina principal com Playwright")
                movimentacoes = await self._extrair_movimentacoes_playwright(session)
            
            # √öltimo recurso: an√°lise geral
            if not movimentacoes:
                logger.info("üîç An√°lise geral como √∫ltimo recurso")
                movimentacoes = await self._extrair_movimentacoes_fallback(session.page)
            
            if movimentacoes:
                # Limpar e melhorar dados extra√≠dos
                movimentacoes = self._processar_movimentacoes_inteligente(movimentacoes)
                
                # Ordenar por n√∫mero (mais recentes primeiro) ou por data se n√£o houver n√∫mero
                movimentacoes = self._ordenar_movimentacoes_inteligente(movimentacoes)
                
                # Log do total antes de aplicar limite
                total_encontradas = len(movimentacoes)
                logger.info(f"üìä Total de movimenta√ß√µes encontradas: {total_encontradas}")
                
                # Aplicar limite se especificado
                if limite and len(movimentacoes) > limite:
                    movimentacoes = movimentacoes[:limite]
                    logger.info(f"‚úÇÔ∏è Limitado a {limite} movimenta√ß√µes mais recentes")
                
                logger.info(f"‚úÖ {len(movimentacoes)} movimenta√ß√µes extra√≠das com sucesso")
            else:
                logger.warning("‚ö†Ô∏è Nenhuma movimenta√ß√£o encontrada")
            
            return movimentacoes
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao extrair movimenta√ß√µes: {e}")
            return []
    
    async def _extrair_movimentacoes_tabela_arquivos_inteligente(self, page: Page) -> List[Movimentacao]:
        """Vers√£o inteligente da extra√ß√£o de movimenta√ß√µes da tabela de arquivos"""
        try:
            movimentacoes = []
            content = await page.content()
            soup = BeautifulSoup(content, 'html.parser')
            
            # ESTRAT√âGIA 1: Verificar se estamos na p√°gina de navega√ß√£o HTML (formato PLUS)
            if "Movimenta√ß√µes Processo" in content and "menuNavegacao" in content:
                logger.info("üîç P√°gina de navega√ß√£o HTML detectada - usando extra√ß√£o especializada")
                return await self._extrair_movimentacoes_navegacao_html(page)
            
            # ESTRAT√âGIA 2: Tentar m√∫ltiplas estrat√©gias para encontrar a tabela
            tabela = soup.find('table', {'id': 'TabelaArquivos'})
            if not tabela:
                # Fallback: procurar qualquer tabela que pare√ßa conter movimenta√ß√µes
                tabelas = soup.find_all('table')
                for t in tabelas:
                    if any(keyword in t.get_text().upper() for keyword in ['MOVIMENTA√á√ÉO', 'ARQUIVOS', 'DATA', 'USU√ÅRIO']):
                        tabela = t
                        break
            
            if not tabela:
                logger.warning("‚ö†Ô∏è Nenhuma tabela de movimenta√ß√µes encontrada")
                return []
            
            # Estrat√©gias m√∫ltiplas para encontrar linhas
            linhas = (
                tabela.find_all('tr', class_=re.compile(r'TabelaLinha|filtro-entrada|linha|row', re.I)) or
                tabela.find_all('tr')[1:] if tabela.find_all('tr') else []
            )
            
            for linha in linhas:
                movimentacao = self._extrair_movimentacao_da_linha_inteligente(linha)
                if movimentacao:
                    movimentacoes.append(movimentacao)
            
            logger.info(f"‚úÖ {len(movimentacoes)} movimenta√ß√µes extra√≠das da tabela")
            return movimentacoes
            
        except Exception as e:
            logger.error(f"‚ùå Erro na extra√ß√£o inteligente da tabela: {e}")
            return []
    
    async def _extrair_movimentacoes_navegacao_html(self, page: Page) -> List[Movimentacao]:
        """Extrai movimenta√ß√µes da estrutura HTML de navega√ß√£o (formato PLUS)"""
        try:
            movimentacoes = []
            content = await page.content()
            soup = BeautifulSoup(content, 'html.parser')
            
            logger.info("üîç Extraindo movimenta√ß√µes da estrutura HTML de navega√ß√£o")
            
            # Encontrar o div de navega√ß√£o
            navegacao_div = soup.find('div', {'id': 'menuNavegacao'})
            if not navegacao_div:
                logger.warning("‚ö†Ô∏è Div menuNavegacao n√£o encontrado")
                return []
            
            # Extrair todas as LIs que cont√™m movimenta√ß√µes
            items = navegacao_div.find_all('li')
            
            for item in items:
                try:
                    texto = item.get_text()
                    
                    # Procurar por padr√£o: n√∫mero - descri√ß√£o
                    match = re.search(r'(\d+)\s*-\s*(.+)', texto)
                    if match:
                        numero = int(match.group(1))
                        descricao_completa = match.group(2).strip()
                        
                        # Separar tipo e descri√ß√£o
                        partes_descricao = descricao_completa.split(' - ', 1)
                        tipo = partes_descricao[0].strip()
                        descricao = partes_descricao[1].strip() if len(partes_descricao) > 1 else ""
                        
                        # Verificar se tem anexos (links dentro do item)
                        links_anexo = item.find_all('a', href=True)
                        tem_anexo = len(links_anexo) > 0
                        codigo_anexo = ""
                        id_movimentacao = ""
                        
                        if tem_anexo and links_anexo:
                            # Extrair informa√ß√µes do primeiro link
                            primeiro_link = links_anexo[0]
                            href = primeiro_link.get('href', '')
                            
                            # Extrair Id_MovimentacaoArquivo e hash
                            match_id = re.search(r'Id_MovimentacaoArquivo=([^&]+)', href)
                            match_hash = re.search(r'hash=([^&]+)', href)
                            
                            if match_id:
                                id_movimentacao = match_id.group(1)
                            if match_hash:
                                codigo_anexo = match_hash.group(1)
                        
                        movimentacao = Movimentacao(
                            numero=numero,
                            tipo=self._limpar_tipo_movimentacao(tipo),
                            descricao=self._limpar_descricao_movimentacao(descricao),
                            data="",  # Data n√£o est√° dispon√≠vel nesta estrutura
                            usuario="",
                            tem_anexo=tem_anexo,
                            codigo_anexo=codigo_anexo,
                            id_movimentacao=id_movimentacao
                        )
                        
                        movimentacoes.append(movimentacao)
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao processar item de navega√ß√£o: {e}")
                    continue
            
            logger.info(f"‚úÖ {len(movimentacoes)} movimenta√ß√µes extra√≠das da estrutura HTML")
            return movimentacoes
            
        except Exception as e:
            logger.error(f"‚ùå Erro na extra√ß√£o HTML de navega√ß√£o: {e}")
            return []
    
    async def _extrair_movimentacoes_pagina_principal_inteligente(self, page: Page) -> List[Movimentacao]:
        """Vers√£o inteligente da extra√ß√£o de movimenta√ß√µes da p√°gina principal"""
        try:
            movimentacoes = []
            content = await page.content()
            soup = BeautifulSoup(content, 'html.parser')
            
            # Procurar por diferentes estruturas que podem conter movimenta√ß√µes
            candidatos = [
                soup.find_all('div', class_=re.compile(r'movimentacao|movimento', re.I)),
                soup.find_all('li', class_=re.compile(r'movimentacao|movimento', re.I)),
                soup.find_all('tr', class_=re.compile(r'movimentacao|movimento', re.I)),
                soup.find_all(['div', 'section', 'article'], string=re.compile(r'movimenta√ß√£o|movimento', re.I))
            ]
            
            for grupo_candidatos in candidatos:
                for elemento in grupo_candidatos:
                    movimentacao = self._extrair_movimentacao_do_elemento_inteligente(elemento)
                    if movimentacao:
                        movimentacoes.append(movimentacao)
                        
                if movimentacoes:  # Se encontrou movimenta√ß√µes, n√£o precisa tentar outras estrat√©gias
                    break
            
            return movimentacoes
            
        except Exception as e:
            logger.error(f"‚ùå Erro na extra√ß√£o inteligente da p√°gina principal: {e}")
            return []
    
    async def _extrair_movimentacoes_navegacao(self, session: Session) -> List[Movimentacao]:
        """Navega para p√°gina de movimenta√ß√µes se necess√°rio"""
        try:
            # Tentar encontrar e clicar em link para movimenta√ß√µes
            scripts_navegacao = [
                "() => { const link = document.querySelector('a[href*=\"movimentacao\"], a[href*=\"movimento\"]'); if(link) { link.click(); return true; } return false; }",
                "() => { const links = document.querySelectorAll('a'); for(let link of links) { if(link.textContent.includes('Moviment')) { link.click(); return true; } } return false; }",
                "() => { const menu = document.querySelector('[onclick*=\"movimentacao\"], [onclick*=\"movimento\"]'); if(menu) { menu.click(); return true; } return false; }"
            ]
            
            for script in scripts_navegacao:
                try:
                    resultado = await session.page.evaluate(script)
                    if resultado:
                        await session.page.wait_for_load_state('networkidle', timeout=30000)
                        
                        # Tentar extrair movimenta√ß√µes da nova p√°gina
                        movimentacoes = await self._extrair_movimentacoes_pagina_principal_inteligente(session.page)
                        if movimentacoes:
                            return movimentacoes
                        break
                except Exception as e:
                    continue
            
            return []
            
        except Exception as e:
            logger.error(f"‚ùå Erro na navega√ß√£o para movimenta√ß√µes: {e}")
            return []
    
    async def _extrair_movimentacoes_fallback(self, page: Page) -> List[Movimentacao]:
        """Estrat√©gia de fallback para extrair qualquer coisa que pare√ßa movimenta√ß√£o"""
        try:
            movimentacoes = []
            content = await page.content()
            soup = BeautifulSoup(content, 'html.parser')
            
            # Procurar por qualquer elemento que contenha padr√µes de movimenta√ß√£o
            elementos_texto = soup.find_all(['p', 'div', 'span', 'td', 'li'])
            
            for elemento in elementos_texto:
                texto = elemento.get_text(strip=True)
                
                # Padr√µes que indicam movimenta√ß√µes
                if self._texto_parece_movimentacao(texto):
                    movimentacao = self._criar_movimentacao_do_texto(texto)
                    if movimentacao:
                        movimentacoes.append(movimentacao)
            
            return movimentacoes
            
        except Exception as e:
            logger.error(f"‚ùå Erro no fallback de movimenta√ß√µes: {e}")
            return []
    
    def _extrair_movimentacao_da_linha_inteligente(self, linha) -> Optional[Movimentacao]:
        """Extrai movimenta√ß√£o de uma linha usando m√∫ltiplas estrat√©gias"""
        try:
            tds = linha.find_all(['td', 'th'])
            if len(tds) < 3:  # M√≠nimo necess√°rio
                return None
            
            # Estrat√©gia adaptativa baseada no n√∫mero de colunas
            numero = self._extrair_numero_movimentacao(tds)
            if numero is None:
                return None
            
            # Extrair informa√ß√µes de forma flex√≠vel
            tipo, descricao = self._extrair_tipo_descricao_inteligente(tds)
            data = self._extrair_data_inteligente(tds)
            usuario = self._extrair_usuario_inteligente(tds)
            tem_anexo, codigo_anexo, id_movimentacao = self._extrair_info_anexo_inteligente(linha, tds)
            
            return Movimentacao(
                numero=numero,
                tipo=tipo,
                descricao=descricao,
                data=data,
                usuario=usuario,
                tem_anexo=tem_anexo,
                id_movimentacao=id_movimentacao,
                codigo_anexo=codigo_anexo
            )
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao extrair movimenta√ß√£o da linha: {e}")
            return None
    
    def _extrair_movimentacao_do_elemento_inteligente(self, elemento) -> Optional[Movimentacao]:
        """Extrai movimenta√ß√£o de um elemento gen√©rico"""
        try:
            texto = elemento.get_text(strip=True)
            if not self._texto_parece_movimentacao(texto):
                return None
            
            return self._criar_movimentacao_do_texto(texto)
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao extrair movimenta√ß√£o do elemento: {e}")
            return None
    
    def _extrair_numero_movimentacao(self, tds) -> Optional[int]:
        """Extrai n√∫mero da movimenta√ß√£o de forma inteligente"""
        for i, td in enumerate(tds[:3]):  # Verificar nas primeiras 3 colunas
            texto = td.get_text(strip=True)
            if texto.isdigit():
                return int(texto)
            
            # Tentar extrair n√∫mero de texto misto
            match = re.search(r'(\d+)', texto)
            if match:
                return int(match.group(1))
        
        return None
    
    def _extrair_tipo_descricao_inteligente(self, tds) -> tuple[str, str]:
        """Extrai tipo e descri√ß√£o de forma inteligente"""
        # Procurar por coluna que contenha span com classe espec√≠fica
        for td in tds:
            span_tipo = td.find('span', class_=re.compile(r'tipo|movimentacao', re.I))
            if span_tipo:
                tipo = span_tipo.get_text(strip=True)
                
                # Descri√ß√£o pode estar ap√≥s <br> ou no restante do texto
                br_element = td.find('br')
                if br_element and br_element.next_sibling:
                    descricao = str(br_element.next_sibling).strip()
                else:
                    descricao = td.get_text(strip=True).replace(tipo, '').strip()
                
                return tipo, descricao
        
        # Fallback: primeira coluna que n√£o √© n√∫mero
        for td in tds:
            texto = td.get_text(strip=True)
            if texto and not texto.isdigit() and not re.match(r'\d{2}/\d{2}/\d{4}', texto):
                return texto, ""
        
        return "Movimenta√ß√£o", ""
    
    def _extrair_data_inteligente(self, tds) -> str:
        """Extrai data de forma inteligente"""
        for td in tds:
            texto = td.get_text(strip=True)
            if re.match(r'\d{2}/\d{2}/\d{4}', texto):
                return texto
        
        return ""
    
    def _extrair_usuario_inteligente(self, tds) -> str:
        """Extrai usu√°rio de forma inteligente"""
        # Usu√°rio geralmente est√° nas √∫ltimas colunas
        for td in reversed(tds):
            texto = td.get_text(strip=True)
            if texto and not re.match(r'\d{2}/\d{2}/\d{4}', texto) and not texto.isdigit():
                # Verificar se parece nome de usu√°rio
                if len(texto) > 3 and ' ' in texto:
                    return texto
        
        return ""
    
    async def _extrair_info_anexo_inteligente_playwright(self, session: Session, linha_element) -> tuple[bool, str, str]:
        """Extrai informa√ß√µes de anexo usando Playwright para detectar links clic√°veis"""
        tem_anexo = False
        codigo_anexo = ""
        id_movimentacao = ""
        
        try:
            # Procurar por links clic√°veis dentro da linha
            links = await linha_element.query_selector_all('a[href], a[onclick]')
            
            for link in links:
                # Verificar se o link est√° relacionado a arquivo
                href = await link.get_attribute('href') or ""
                onclick = await link.get_attribute('onclick') or ""
                texto_link = await link.inner_text()
                
                # Padr√µes que indicam anexo
                if (any(ext in texto_link.lower() for ext in ['.pdf', '.doc', '.docx', '.jpg', '.png', 'arquivo', 'anexo', 'documento']) or
                    any(pattern in href.lower() for pattern in ['arquivo', 'anexo', 'documento', 'download']) or
                    any(pattern in onclick.lower() for pattern in ['arquivo', 'anexo', 'documento', 'buscarArquivos'])):
                    
                    tem_anexo = True
                    
                    # Extrair c√≥digo do anexo do onclick
                    match = re.search(r"buscarArquivosMovimentacaoJSON\('([^']+)'", onclick)
                    if match:
                        codigo_anexo = match.group(1)
                    break
            
            # Se n√£o encontrou links, usar estrat√©gia de texto
            if not tem_anexo:
                texto_linha = await linha_element.inner_text()
                
                # Procurar por extens√µes de arquivo ou palavras-chave
                palavras_anexo = ['.pdf', '.doc', '.docx', '.jpg', '.png', 'anexo', 'arquivo', 'documento', 'peti√ß√£o', 'certid√£o', 'digitalizada']
                
                for palavra in palavras_anexo:
                    if palavra in texto_linha.lower():
                        tem_anexo = True
                        break
            
            return tem_anexo, codigo_anexo, id_movimentacao
            
        except Exception as e:
            # Fallback para m√©todo original em caso de erro
            return False, "", ""
    
    def _extrair_info_anexo_inteligente(self, linha, tds) -> tuple[bool, str, str]:
        """Extrai informa√ß√µes de anexo de forma inteligente (m√©todo legado para compatibilidade)"""
        tem_anexo = False
        codigo_anexo = ""
        id_movimentacao = ""
        
        # Converter linha para string para busca mais ampla
        linha_html = str(linha)
        
        # Estrat√©gia 1: Procurar por imagens que indicam anexos
        for td in tds:
            if td.find('img', {'src': re.compile(r'anexo|arquivo|go-bottom|documento|pdf|attach', re.I)}):
                tem_anexo = True
                
                # Procurar por link com c√≥digo do anexo
                link_anexo = td.find('a')
                if link_anexo:
                    onclick = link_anexo.get('onclick', '')
                    match = re.search(r"buscarArquivosMovimentacaoJSON\('([^']+)'", onclick)
                    if match:
                        codigo_anexo = match.group(1)
                break
        
        # Estrat√©gia 2: Procurar por palavras-chave que indicam anexos no texto
        if not tem_anexo:
            palavras_anexo = ['.pdf', '.doc', '.docx', '.jpg', '.png', 'anexo', 'arquivo', 'documento', 'peti√ß√£o', 'certid√£o', 'digitalizada']
            texto_linha = linha.get_text().lower()
            
            for palavra in palavras_anexo:
                if palavra in texto_linha.lower():
                    tem_anexo = True
                    break
        
        # Estrat√©gia 3: Procurar por links ou onclick relacionados a arquivos
        if not tem_anexo:
            if re.search(r'(arquivo|anexo|documento|pdf)', linha_html, re.I):
                tem_anexo = True
        
        # Estrat√©gia 4: Procurar por padr√µes de ID de arquivo
        if not tem_anexo:
            if re.search(r'id_arquivo|arquivo_\d+|anexo_\d+', linha_html, re.I):
                tem_anexo = True
        
        # Procurar ID da movimenta√ß√£o
        div_drop = linha.find('div', class_=re.compile(r'drop|movimentacao', re.I))
        if div_drop:
            id_movimentacao = div_drop.get('id_movi', '') or div_drop.get('id', '')
        
        return tem_anexo, codigo_anexo, id_movimentacao
    
    async def _extrair_movimentacoes_playwright(self, session: Session) -> List[Movimentacao]:
        """Extrai movimenta√ß√µes usando Playwright para detectar anexos corretamente"""
        try:
            movimentacoes = []
            
            # Procurar por elementos que contenham movimenta√ß√µes na p√°gina atual
            possible_selectors = [
                'div.drop',  # Divs com classe drop
                'tr[id*="movi"]',  # Linhas com ID contendo "movi"
                'div[id*="movi"]',  # Divs com ID contendo "movi"
                '.movimentacao',  # Classe movimentacao
                'div:has-text("Movimenta√ß√£o")',  # Divs que cont√™m a palavra "Movimenta√ß√£o"
            ]
            
            for selector in possible_selectors:
                try:
                    elementos = await session.page.query_selector_all(selector)
                    
                    for elemento in elementos:
                        # Extrair texto do elemento
                        texto = await elemento.inner_text()
                        
                        if self._texto_parece_movimentacao(texto):
                            # Extrair n√∫mero da movimenta√ß√£o
                            numero = self._extrair_numero_movimentacao(texto)
                            
                            # Extrair tipo e descri√ß√£o
                            tipo, descricao = self._extrair_tipo_descricao(texto)
                            
                            # Extrair data
                            data = self._extrair_data_movimentacao(texto)
                            
                            # Extrair informa√ß√µes de anexo usando Playwright
                            tem_anexo, codigo_anexo, id_movimentacao = await self._extrair_info_anexo_inteligente_playwright(
                                session, elemento
                            )
                            
                            movimentacao = Movimentacao(
                                numero=numero,
                                tipo=tipo,
                                descricao=descricao,
                                data=data,
                                usuario="",
                                tem_anexo=tem_anexo,
                                codigo_anexo=codigo_anexo,
                                id_movimentacao=id_movimentacao
                            )
                            
                            movimentacoes.append(movimentacao)
                    
                    if movimentacoes:
                        break  # Se encontrou movimenta√ß√µes, parar
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro com seletor {selector}: {e}")
                    continue
            
            logger.info(f"‚úÖ {len(movimentacoes)} movimenta√ß√µes extra√≠das com Playwright")
            return movimentacoes
            
        except Exception as e:
            logger.error(f"‚ùå Erro na extra√ß√£o com Playwright: {e}")
            return []
    
    def _texto_parece_movimentacao(self, texto: str) -> bool:
        """Verifica se o texto parece ser uma movimenta√ß√£o"""
        if len(texto) < 10:
            return False
        
        # Padr√µes que indicam movimenta√ß√µes
        padroes_movimentacao = [
            r'\d+\s*-\s*.+\d{2}/\d{2}/\d{4}',  # N√∫mero - Descri√ß√£o Data
            r'Movimenta√ß√£o\s*\d+',
            r'^\d+\.\s*.+',  # N√∫mero. Descri√ß√£o
            r'\d{2}/\d{2}/\d{4}.*por.*'  # Data ... por usu√°rio
        ]
        
        for padrao in padroes_movimentacao:
            if re.search(padrao, texto, re.I):
                return True
        
        return False
    
    def _criar_movimentacao_do_texto(self, texto: str) -> Optional[Movimentacao]:
        """Cria movimenta√ß√£o a partir de texto livre"""
        try:
            # Tentar extrair n√∫mero
            match_numero = re.search(r'^(\d+)', texto)
            numero = int(match_numero.group(1)) if match_numero else 0
            
            # Tentar extrair data
            match_data = re.search(r'(\d{2}/\d{2}/\d{4})', texto)
            data = match_data.group(1) if match_data else ""
            
            # Tentar extrair usu√°rio (ap√≥s "por")
            match_usuario = re.search(r'por\s+([^,\n]+)', texto, re.I)
            usuario = match_usuario.group(1).strip() if match_usuario else ""
            
            # Resto √© tipo/descri√ß√£o
            descricao = re.sub(r'^\d+[.\-\s]*', '', texto)  # Remover n√∫mero inicial
            descricao = re.sub(r'\d{2}/\d{2}/\d{4}.*', '', descricao)  # Remover data e ap√≥s
            descricao = descricao.strip()
            
            return Movimentacao(
                numero=numero,
                tipo="Movimenta√ß√£o",
                descricao=descricao,
                data=data,
                usuario=usuario,
                tem_anexo=False,
                id_movimentacao="",
                codigo_anexo=""
            )
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao criar movimenta√ß√£o do texto: {e}")
            return None
    
    def _processar_movimentacoes_inteligente(self, movimentacoes: List[Movimentacao]) -> List[Movimentacao]:
        """Processa e melhora dados das movimenta√ß√µes"""
        movimentacoes_processadas = []
        
        for mov in movimentacoes:
            # Limpar e melhorar dados
            mov_processada = Movimentacao(
                numero=mov.numero,
                tipo=self._limpar_tipo_movimentacao(mov.tipo),
                descricao=self._limpar_descricao_movimentacao(mov.descricao),
                data=self._normalizar_data(mov.data),
                usuario=self._limpar_nome_usuario(mov.usuario),
                tem_anexo=mov.tem_anexo,
                id_movimentacao=mov.id_movimentacao,
                codigo_anexo=mov.codigo_anexo
            )
            
            movimentacoes_processadas.append(mov_processada)
        
        return movimentacoes_processadas
    
    def _ordenar_movimentacoes_inteligente(self, movimentacoes: List[Movimentacao]) -> List[Movimentacao]:
        """Ordena movimenta√ß√µes de forma inteligente"""
        try:
            # Primeira tentativa: ordenar por n√∫mero (mais recentes primeiro)
            if all(mov.numero > 0 for mov in movimentacoes):
                return sorted(movimentacoes, key=lambda x: x.numero, reverse=True)
            
            # Segunda tentativa: ordenar por data
            movs_com_data = [mov for mov in movimentacoes if mov.data]
            if movs_com_data:
                from datetime import datetime
                def data_para_datetime(data_str):
                    try:
                        return datetime.strptime(data_str, '%d/%m/%Y')
                    except:
                        return datetime.min
                
                return sorted(movimentacoes, key=lambda x: data_para_datetime(x.data), reverse=True)
            
            # Fallback: manter ordem original
            return movimentacoes
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao ordenar movimenta√ß√µes: {e}")
            return movimentacoes
    
    def _limpar_tipo_movimentacao(self, tipo: str) -> str:
        """Limpa e normaliza tipo de movimenta√ß√£o"""
        if not tipo:
            return "Movimenta√ß√£o"
        
        # Remover HTML tags se houver
        tipo = re.sub(r'<[^>]+>', '', tipo)
        
        # Limpar espa√ßos e caracteres especiais
        tipo = re.sub(r'\s+', ' ', tipo).strip()
        
        return tipo
    
    def _limpar_descricao_movimentacao(self, descricao: str) -> str:
        """Limpa e normaliza descri√ß√£o de movimenta√ß√£o"""
        if not descricao:
            return ""
        
        # Remover HTML tags
        descricao = re.sub(r'<[^>]+>', '', descricao)
        
        # Limpar espa√ßos extras e quebras de linha
        descricao = re.sub(r'\s+', ' ', descricao).strip()
        
        return descricao
    
    def _normalizar_data(self, data: str) -> str:
        """Normaliza formato de data"""
        if not data:
            return ""
        
        # Extrair data no formato dd/mm/yyyy
        match = re.search(r'(\d{1,2}/\d{1,2}/\d{4})', data)
        return match.group(1) if match else data
    
    def _limpar_nome_usuario(self, usuario: str) -> str:
        """Limpa nome do usu√°rio"""
        if not usuario:
            return ""
        
        # Remover prefixos comuns
        usuario = re.sub(r'^(por|by|user|usuario):\s*', '', usuario, flags=re.I)
        
        # Limpar espa√ßos
        usuario = re.sub(r'\s+', ' ', usuario).strip()
        
        return usuario
    
    async def _extrair_movimentacoes_tabela_arquivos(self, page: Page) -> List[Movimentacao]:
        """Extrai movimenta√ß√µes da tabela de arquivos (p√°gina de navega√ß√£o)"""
        try:
            movimentacoes = []
            content = await page.content()
            soup = BeautifulSoup(content, 'html.parser')
            
            tabela = soup.find('table', {'id': 'TabelaArquivos'})
            if not tabela:
                return []
            
            linhas = tabela.find_all('tr', class_=re.compile(r'TabelaLinha|filtro-entrada'))
            if not linhas:
                linhas = tabela.find_all('tr')[1:]  # Pular cabe√ßalho
            
            for linha in linhas:
                tds = linha.find_all('td')
                if len(tds) >= 5:
                    try:
                        numero_text = tds[0].get_text(strip=True)
                        if not numero_text.isdigit():
                            continue
                            
                        numero = int(numero_text)
                        
                        # Extrair tipo e descri√ß√£o da movimenta√ß√£o
                        movimentacao_celula = tds[1]
                        span_tipo = movimentacao_celula.find('span', class_='filtro_tipo_movimentacao')
                        
                        if span_tipo:
                            tipo = span_tipo.get_text(strip=True)
                            # Descri√ß√£o vem ap√≥s o <br>
                            br_element = movimentacao_celula.find('br')
                            if br_element and br_element.next_sibling:
                                descricao = str(br_element.next_sibling).strip()
                            else:
                                descricao = movimentacao_celula.get_text(strip=True).replace(tipo, '').strip()
                        else:
                            tipo = movimentacao_celula.get_text(strip=True)
                            descricao = ""
                        
                        data = tds[2].get_text(strip=True)
                        usuario = tds[3].get_text(strip=True)
                        
                        # Verificar se tem anexo
                        arquivos_celula = tds[4]
                        tem_anexo = bool(arquivos_celula.find('img', {'src': 'imagens/22x22/go-bottom.png'}))
                        
                        # Extrair c√≥digo de anexo se houver
                        codigo_anexo = ""
                        if tem_anexo:
                            link_anexo = arquivos_celula.find('a')
                            if link_anexo:
                                onclick = link_anexo.get('onclick', '')
                                match = re.search(r"buscarArquivosMovimentacaoJSON\('([^']+)'", onclick)
                                if match:
                                    codigo_anexo = match.group(1)
                        
                        # Extrair ID da movimenta√ß√£o
                        id_movimentacao = ""
                        div_drop = linha.find('div', class_='dropMovimentacao')
                        if div_drop:
                            id_movimentacao = div_drop.get('id_movi', '')
                        
                        movimentacao = Movimentacao(
                            numero=numero,
                            tipo=tipo,
                            descricao=descricao,
                            data=data,
                            usuario=usuario,
                            tem_anexo=tem_anexo,
                            id_movimentacao=id_movimentacao,
                            codigo_anexo=codigo_anexo,
                            html_completo=str(linha)
                        )
                        
                        movimentacoes.append(movimentacao)
                        
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Erro ao processar linha de movimenta√ß√£o: {e}")
                        continue
            
            return movimentacoes
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao extrair movimenta√ß√µes da tabela: {e}")
            return []
    
    async def _extrair_movimentacoes_pagina_principal(self, page: Page) -> List[Movimentacao]:
        """Extrai movimenta√ß√µes da p√°gina principal do processo"""
        try:
            content = await page.content()
            soup = BeautifulSoup(content, 'html.parser')
            movimentacoes = []
            
            # Procurar por elementos que cont√™m movimenta√ß√µes
            elementos_mov = soup.find_all(['div', 'tr'], class_=re.compile(r'movimentacao|movimento'))
            
            for i, elemento in enumerate(elementos_mov):
                try:
                    texto = elemento.get_text(strip=True)
                    if len(texto) > 20:  # Filtrar textos muito curtos
                        # Detectar anexos de forma inteligente
                        tem_anexo = self._detectar_anexo_movimentacao(texto, str(elemento))
                        
                        movimentacao = Movimentacao(
                            numero=i + 1,
                            tipo="Movimenta√ß√£o",
                            descricao=texto[:200],  # Limitar tamanho
                            data="",
                            usuario="",
                            tem_anexo=tem_anexo,
                            id_movimentacao=f"mov_{i}",
                            html_completo=str(elemento)
                        )
                        movimentacoes.append(movimentacao)
                        
                except Exception as e:
                    continue
            
            return movimentacoes
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao extrair movimenta√ß√µes da p√°gina principal: {e}")
            return []
    
    def _detectar_anexo_movimentacao(self, texto: str, html_completo: str) -> bool:
        """Detecta se uma movimenta√ß√£o tem anexo baseado no texto e HTML"""
        try:
            # Palavras-chave EXPANDIDAS que indicam anexos
            palavras_anexo = [
                # Anexos expl√≠citos
                'anexo', 'anexos', 'anexado', 'anexa', 'anexar',
                'arquivo', 'arquivos', 'arq.', 'file', 'files',
                'documento', 'documentos', 'doc', 'docs',
                
                # Extens√µes de arquivo
                '.pdf', '.doc', '.docx', '.html', '.txt', '.jpg', '.jpeg', '.png',
                '.zip', '.rar', '.xml', '.xls', '.xlsx', '.odt', '.rtf',
                
                # Tipos de documentos jur√≠dicos
                'peti√ß√£o', 'peticao', 'peti√ß√£o inicial', 'contesta√ß√£o', 'contestacao',
                'certid√£o', 'certidao', 'comprovante', 'declara√ß√£o', 'declaracao',
                'ata', 'termo', 'relat√≥rio', 'relatorio', 'laudo',
                'procura√ß√£o', 'procuracao', 'substabelecimento',
                
                # A√ß√µes de upload/envio
                'upload', 'envio', 'enviado', 'juntada', 'juntado',
                'protocolado', 'protocolo', 'digitalizado',
                
                # Indicadores visuais comuns
                'visualizar', 'baixar', 'download', 'ver anexo',
                'clique aqui', 'acesse', 'consulte'
            ]
            
            # Verificar no texto
            texto_lower = texto.lower()
            for palavra in palavras_anexo:
                if palavra in texto_lower:
                    return True
            
            # Verificar no HTML (links, bot√µes, √≠cones) - EXPANDIDO
            html_lower = html_completo.lower()
            indicadores_html = [
                # Links diretos
                'href=', 'src=', 'url=', 'link=',
                
                # Atributos de download
                'download', 'attachment', 'file', 'documento',
                
                # Classes e IDs CSS comuns
                'icon-download', 'icon-file', 'icon-pdf', 'icon-attach',
                'btn-download', 'btn-file', 'btn-anexo', 'link-arquivo',
                'file-link', 'doc-link', 'anexo-link',
                
                # A√ß√µes e comandos
                'visualizar', 'baixar', 'abrir', 'acessar',
                'onclick', 'javascript:', 'window.open',
                
                # Indicadores de arquivo espec√≠ficos
                'pdf', 'doc', 'arquivo', 'anexo',
                'target="_blank"', 'new window', 'nova janela'
            ]
            
            for indicador in indicadores_html:
                if indicador in html_lower:
                    return True
                    
            return False
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao detectar anexo: {e}")
            return False
    
    async def _extrair_partes_fallback_texto(self, page: Page) -> Dict[str, List[ParteEnvolvida]]:
        """Extra√ß√£o de partes por an√°lise de texto como √∫ltimo recurso"""
        try:
            content = await page.content()
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(content, 'html.parser')
            
            partes = {'polo_ativo': [], 'polo_passivo': [], 'outros': []}
            texto_completo = soup.get_text()
            
            # Procurar padr√µes de nomes (palavras em mai√∫sculo seguidas)
            import re
            nomes_encontrados = re.findall(r'[A-Z√Å√ä√á√ï][A-Za-z√°√™√ß√µ\s]{15,60}', texto_completo)
            
            # Procurar CPFs e CNPJs
            cpfs = re.findall(r'\d{3}\.\d{3}\.\d{3}-\d{2}', texto_completo)
            cnpjs = re.findall(r'\d{2}\.\d{3}\.\d{3}/\d{4}-\d{2}', texto_completo)
            
            logger.info(f"üîç Encontrados: {len(nomes_encontrados)} nomes, {len(cpfs)} CPFs, {len(cnpjs)} CNPJs")
            
            # Adicionar pessoas f√≠sicas
            for cpf in cpfs:
                parte = ParteEnvolvida(
                    nome=f"Pessoa com CPF {cpf}",
                    tipo="Pessoa F√≠sica",
                    documento=cpf,
                    endereco="",
                    telefone="",
                    advogado=""
                )
                partes['outros'].append(parte)
            
            # Adicionar pessoas jur√≠dicas
            for cnpj in cnpjs:
                parte = ParteEnvolvida(
                    nome=f"Empresa com CNPJ {cnpj}",
                    tipo="Pessoa Jur√≠dica", 
                    documento=cnpj,
                    endereco="",
                    telefone="",
                    advogado=""
                )
                partes['outros'].append(parte)
            
            # Adicionar nomes √∫nicos
            nomes_unicos = list(set([nome.strip() for nome in nomes_encontrados if len(nome.strip()) > 15]))[:5]
            for nome in nomes_unicos:
                parte = ParteEnvolvida(
                    nome=nome.strip(),
                    tipo="Parte Envolvida",
                    documento="",
                    endereco="",
                    telefone="",
                    advogado=""
                )
                partes['outros'].append(parte)
            
            total_partes = sum(len(p) for p in partes.values())
            logger.info(f"‚úÖ Fallback: {total_partes} partes extra√≠das")
            
            return partes
            
        except Exception as e:
            logger.error(f"‚ùå Erro no fallback de partes: {e}")
            return {'polo_ativo': [], 'polo_passivo': [], 'outros': []}
    
    async def _extrair_partes_envolvidas(self, session: Session) -> Dict[str, List[ParteEnvolvida]]:
        """Extrai partes envolvidas no processo"""
        try:
            logger.info("üë• Extraindo partes envolvidas...")
            
            # Verificar se estamos na p√°gina correta do processo
            url_atual = session.page.url
            content_inicial = await session.page.content()
            
            # Verifica√ß√£o mais flex√≠vel - tentamos extrair independente da p√°gina
            logger.info(f"üîç URL atual: {url_atual}")
            logger.info(f"üîç Procurando partes na p√°gina atual...")
            
            # Se n√£o estamos em p√°gina espec√≠fica, tentar extrair da p√°gina atual mesmo assim
            if "corpo_dados_processo" not in content_inicial and "ProcessoParte" not in url_atual:
                logger.info("‚ö†Ô∏è Tentando extrair partes da p√°gina atual mesmo sem indicadores espec√≠ficos")
            
            partes = {
                'polo_ativo': [],
                'polo_passivo': [],
                'outros': []
            }
            
            # ESTRAT√âGIA ROBUSTA: Extrair partes da p√°gina atual SEM navegar
            logger.info("üîç Extraindo partes da p√°gina atual...")
            partes = await self._extrair_partes_da_pagina(session.page)
            
            # Se n√£o encontrou na p√°gina atual, tentar navegar (sem timeout longo)
            if not any(partes.values()):
                logger.info("üîç Tentando acessar p√°gina espec√≠fica de partes...")
                try:
                    # URL mais direta e confi√°vel
                    url_partes = f"{self.base_url}/ProcessoParte?PaginaAtual=2"
                    await session.page.goto(url_partes, timeout=10000, wait_until='domcontentloaded')
                    await asyncio.sleep(1)  # Aguardar m√≠nimo
                    
                    # Verificar se carregou
                    content = await session.page.content()
                    if "Usu√°rio inv√°lido" not in content and "erro" not in content.lower():
                        partes = await self._extrair_partes_da_pagina(session.page)
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Navega√ß√£o para partes falhou: {e}")
                    # Continuar com p√°gina atual
            
            # FALLBACK FINAL: Extra√ß√£o inteligente de texto da p√°gina atual
            if not any(partes.values()):
                logger.info("üîç Fallback: Extraindo partes por an√°lise de texto...")
                partes = await self._extrair_partes_fallback_texto(session.page)
            
            total_partes = sum(len(p) for p in partes.values())
            logger.info(f"‚úÖ {total_partes} partes extra√≠das")
            return partes
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao extrair partes envolvidas: {e}")
            return {'polo_ativo': [], 'polo_passivo': [], 'outros': []}
    
    async def _extrair_partes_da_pagina(self, page: Page) -> Dict[str, List[ParteEnvolvida]]:
        """Extrai partes de uma p√°gina espec√≠fica com m√∫ltiplas estrat√©gias inteligentes"""
        try:
            content = await page.content()
            soup = BeautifulSoup(content, 'html.parser')
            
            partes = {
                'polo_ativo': [],
                'polo_passivo': [],
                'outros': []
            }
            
            logger.info("üîç Iniciando extra√ß√£o inteligente de partes...")
            
            # Estrat√©gia 1: Fieldsets com legendas (mais comum)
            partes_fieldsets = self._extrair_partes_fieldsets(soup)
            if any(partes_fieldsets.values()):
                logger.info(f"‚úÖ Estrat√©gia 1 (Fieldsets): Encontradas {sum(len(v) for v in partes_fieldsets.values())} partes")
                for categoria, lista_partes in partes_fieldsets.items():
                    partes[categoria].extend(lista_partes)
            
            # Estrat√©gia 2: Tabelas estruturadas
            if not any(partes.values()):
                partes_tabelas = self._extrair_partes_tabelas(soup)
                if any(partes_tabelas.values()):
                    logger.info(f"‚úÖ Estrat√©gia 2 (Tabelas): Encontradas {sum(len(v) for v in partes_tabelas.values())} partes")
                    for categoria, lista_partes in partes_tabelas.items():
                        partes[categoria].extend(lista_partes)
            
            # Estrat√©gia 3: Divs com classes espec√≠ficas
            if not any(partes.values()):
                partes_divs = self._extrair_partes_divs(soup)
                if any(partes_divs.values()):
                    logger.info(f"‚úÖ Estrat√©gia 3 (Divs): Encontradas {sum(len(v) for v in partes_divs.values())} partes")
                    for categoria, lista_partes in partes_divs.items():
                        partes[categoria].extend(lista_partes)
            
            # Estrat√©gia 4: An√°lise de texto estruturado
            if not any(partes.values()):
                partes_texto = self._extrair_partes_texto_inteligente(soup)
                if any(partes_texto.values()):
                    logger.info(f"‚úÖ Estrat√©gia 4 (Texto): Encontradas {sum(len(v) for v in partes_texto.values())} partes")
                    for categoria, lista_partes in partes_texto.items():
                        partes[categoria].extend(lista_partes)
            
            # Estrat√©gia 5: Fallback - busca geral por padr√µes
            if not any(partes.values()):
                partes_fallback = self._extrair_partes_fallback(soup)
                if any(partes_fallback.values()):
                    logger.info(f"‚úÖ Estrat√©gia 5 (Fallback): Encontradas {sum(len(v) for v in partes_fallback.values())} partes")
                    for categoria, lista_partes in partes_fallback.items():
                        partes[categoria].extend(lista_partes)
            
            # Remover duplicatas mantendo informa√ß√µes mais completas
            partes = self._remover_duplicatas_partes(partes)
            
            total_partes = sum(len(v) for v in partes.values())
            logger.info(f"üéØ Total final: {total_partes} partes √∫nicas extra√≠das")
            
            return partes
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao extrair partes da p√°gina: {e}")
            return {'polo_ativo': [], 'polo_passivo': [], 'outros': []}
    
    def _extrair_partes_fieldsets(self, soup) -> Dict[str, List[ParteEnvolvida]]:
        """Estrat√©gia 1: Extrai partes de fieldsets com legendas"""
        partes = {'polo_ativo': [], 'polo_passivo': [], 'outros': []}
        
        fieldsets = soup.find_all('fieldset')
        for fieldset in fieldsets:
            legend = fieldset.find('legend')
            if legend:
                titulo = legend.get_text(strip=True).upper()
                
                if any(palavra in titulo for palavra in ['POLO ATIVO', 'REQUERENTE', 'AUTOR']):
                    partes['polo_ativo'].extend(self._extrair_partes_do_fieldset(fieldset, 'Polo Ativo'))
                elif any(palavra in titulo for palavra in ['POLO PASSIVO', 'REQUERIDO', 'R√âU', 'EXECUTADO']):
                    partes['polo_passivo'].extend(self._extrair_partes_do_fieldset(fieldset, 'Polo Passivo'))
                elif any(palavra in titulo for palavra in ['OUTRAS', 'SUJEITOS', 'TERCEIRO', 'INTERVENIENTE']):
                    partes['outros'].extend(self._extrair_partes_do_fieldset(fieldset, 'Outras'))
        
        return partes
    
    def _extrair_partes_tabelas(self, soup) -> Dict[str, List[ParteEnvolvida]]:
        """Estrat√©gia 2: Extrai partes de tabelas estruturadas"""
        partes = {'polo_ativo': [], 'polo_passivo': [], 'outros': []}
        
        # Procurar tabelas que podem conter partes
        tabelas = soup.find_all('table')
        for tabela in tabelas:
            # Analisar cabe√ßalhos para identificar tipo de parte
            thead = tabela.find('thead')
            tbody = tabela.find('tbody')
            
            if not tbody:
                tbody = tabela  # Usar a pr√≥pria tabela se n√£o h√° tbody
            
            # Procurar por indicadores de tipo de parte
            texto_tabela = tabela.get_text().upper()
            
            tipo_parte = 'outros'
            if any(palavra in texto_tabela for palavra in ['POLO ATIVO', 'REQUERENTE', 'AUTOR']):
                tipo_parte = 'polo_ativo'
            elif any(palavra in texto_tabela for palavra in ['POLO PASSIVO', 'REQUERIDO', 'R√âU']):
                tipo_parte = 'polo_passivo'
            
            # Extrair partes das linhas da tabela
            linhas = tbody.find_all('tr')
            for linha in linhas:
                parte = self._extrair_parte_da_linha_tabela(linha, tipo_parte)
                if parte:
                    partes[tipo_parte].append(parte)
        
        return partes
    
    def _extrair_partes_divs(self, soup) -> Dict[str, List[ParteEnvolvida]]:
        """Estrat√©gia 3: Extrai partes de divs com classes espec√≠ficas"""
        partes = {'polo_ativo': [], 'polo_passivo': [], 'outros': []}
        
        # Procurar divs que podem conter informa√ß√µes de partes
        divs_candidatos = soup.find_all('div', class_=re.compile(r'parte|polo|sujeito', re.I))
        
        for div in divs_candidatos:
            texto_div = div.get_text().upper()
            
            tipo_parte = 'outros'
            if any(palavra in texto_div for palavra in ['POLO ATIVO', 'REQUERENTE', 'AUTOR']):
                tipo_parte = 'polo_ativo'
            elif any(palavra in texto_div for palavra in ['POLO PASSIVO', 'REQUERIDO', 'R√âU']):
                tipo_parte = 'polo_passivo'
            
            parte = self._extrair_parte_do_elemento(div, tipo_parte)
            if parte:
                partes[tipo_parte].append(parte)
        
        return partes
    
    def _extrair_partes_texto_inteligente(self, soup) -> Dict[str, List[ParteEnvolvida]]:
        """Estrat√©gia 4: An√°lise inteligente de texto estruturado"""
        partes = {'polo_ativo': [], 'polo_passivo': [], 'outros': []}
        
        texto_completo = soup.get_text()
        
        # Padr√µes para identificar se√ß√µes de partes
        padroes_secoes = [
            (r'POLO ATIVO[:\s]*\n(.*?)(?=POLO PASSIVO|$)', 'polo_ativo'),
            (r'POLO PASSIVO[:\s]*\n(.*?)(?=POLO ATIVO|OUTRAS|$)', 'polo_passivo'),
            (r'REQUERENTE[:\s]*\n(.*?)(?=REQUERIDO|$)', 'polo_ativo'),
            (r'REQUERIDO[:\s]*\n(.*?)(?=REQUERENTE|$)', 'polo_passivo'),
            (r'AUTOR[:\s]*\n(.*?)(?=R√âU|$)', 'polo_ativo'),
            (r'R√âU[:\s]*\n(.*?)(?=AUTOR|$)', 'polo_passivo'),
        ]
        
        for padrao, tipo_parte in padroes_secoes:
            matches = re.finditer(padrao, texto_completo, re.MULTILINE | re.IGNORECASE | re.DOTALL)
            for match in matches:
                secao_texto = match.group(1)
                partes_secao = self._extrair_partes_do_texto_secao(secao_texto, tipo_parte)
                partes[tipo_parte].extend(partes_secao)
        
        return partes
    
    def _extrair_partes_fallback(self, soup) -> Dict[str, List[ParteEnvolvida]]:
        """Estrat√©gia 5: Fallback - busca geral por padr√µes de nomes"""
        partes = {'polo_ativo': [], 'polo_passivo': [], 'outros': []}
        
        # Procurar por qualquer elemento que contenha padr√µes de nomes de pessoas
        elementos_texto = soup.find_all(['p', 'div', 'span', 'td', 'li'])
        
        for elemento in elementos_texto:
            texto = elemento.get_text(strip=True)
            
            # Padr√µes que indicam nomes de pessoas
            if self._parece_nome_pessoa(texto):
                # Tentar determinar o tipo baseado no contexto
                contexto = self._obter_contexto_elemento(elemento)
                tipo_parte = self._determinar_tipo_parte_contexto(contexto)
                
                parte = ParteEnvolvida(
                    nome=self._limpar_nome_parte(texto),
                    tipo=tipo_parte.replace('_', ' ').title(),
                    documento=self._extrair_documento_texto(texto),
                    endereco=self._extrair_endereco_texto(texto)
                )
                
                partes[tipo_parte].append(parte)
        
        return partes
    
    def _remover_duplicatas_partes(self, partes: Dict[str, List[ParteEnvolvida]]) -> Dict[str, List[ParteEnvolvida]]:
        """Remove duplicatas mantendo as informa√ß√µes mais completas"""
        partes_unicas = {'polo_ativo': [], 'polo_passivo': [], 'outros': []}
        
        for categoria, lista_partes in partes.items():
            nomes_vistos = set()
            
            for parte in lista_partes:
                nome_normalizado = self._normalizar_nome_para_comparacao(parte.nome)
                
                if nome_normalizado not in nomes_vistos and nome_normalizado:
                    nomes_vistos.add(nome_normalizado)
                    partes_unicas[categoria].append(parte)
                else:
                    # Se j√° existe, manter a que tem mais informa√ß√µes
                    for i, parte_existente in enumerate(partes_unicas[categoria]):
                        if self._normalizar_nome_para_comparacao(parte_existente.nome) == nome_normalizado:
                            if self._parte_tem_mais_informacoes(parte, parte_existente):
                                partes_unicas[categoria][i] = parte
                            break
        
        return partes_unicas
    
    def _normalizar_nome_para_comparacao(self, nome: str) -> str:
        """Normaliza nome para compara√ß√£o de duplicatas"""
        if not nome:
            return ""
        
        # Remover acentos, converter para mai√∫scula, remover espa√ßos extras
        import unicodedata
        nome_normalizado = unicodedata.normalize('NFD', nome)
        nome_normalizado = ''.join(c for c in nome_normalizado if unicodedata.category(c) != 'Mn')
        nome_normalizado = re.sub(r'\s+', ' ', nome_normalizado.upper().strip())
        
        return nome_normalizado
    
    def _parte_tem_mais_informacoes(self, parte1: ParteEnvolvida, parte2: ParteEnvolvida) -> bool:
        """Verifica qual parte tem mais informa√ß√µes"""
        campos_parte1 = sum(1 for campo in [parte1.documento, parte1.endereco, parte1.telefone, parte1.email, parte1.advogado] if campo)
        campos_parte2 = sum(1 for campo in [parte2.documento, parte2.endereco, parte2.telefone, parte2.email, parte2.advogado] if campo)
        
        return campos_parte1 > campos_parte2
    
    def _parece_nome_pessoa(self, texto: str) -> bool:
        """Verifica se o texto parece ser um nome de pessoa"""
        if not texto or len(texto) < 5:
            return False
        
        # Padr√µes que indicam nomes de pessoas
        padroes_nome = [
            r'^[A-Z√Ä-≈∏][a-z√†-√ø]+ [A-Z√Ä-≈∏][a-z√†-√ø]+',  # Nome Sobrenome
            r'[A-Z√Ä-≈∏][a-z√†-√ø]+ [A-Z√Ä-≈∏][a-z√†-√ø]+ [A-Z√Ä-≈∏][a-z√†-√ø]+',  # Nome Meio Sobrenome
        ]
        
        for padrao in padroes_nome:
            if re.search(padrao, texto):
                return True
        
        return False
    
    def _parece_endereco(self, texto: str) -> bool:
        """Verifica se o texto parece ser um endere√ßo"""
        if not texto:
            return False
        
        texto_lower = texto.lower()
        
        # Padr√µes que indicam endere√ßos
        padroes_endereco = [
            r'\b(rua|av|avenida|travessa|alameda|pra√ßa|quadra|lote|qd|lt|bloco|ap|apartamento)\b',
            r'\bn¬∫?\s*\d+',  # n√∫mero da casa/pr√©dio
            r'\bqd\.?\s*\d+',  # quadra
            r'\blt\.?\s*\d+',  # lote
            r'\bcep\s*:?\s*\d{5}-?\d{3}',  # CEP
            r'\b\d{5}-?\d{3}\b',  # CEP sem prefixo
        ]
        
        for padrao in padroes_endereco:
            if re.search(padrao, texto_lower):
                return True
        
        # Verificar se cont√©m cidade/estado comuns
        if any(cidade in texto_lower for cidade in ['caldas novas', 'goi√¢nia', 'bras√≠lia', 'go', 'df', 'sp']):
            return True
            
        return False
    
    def _parece_nome_valido(self, texto: str) -> bool:
        """Verifica se o texto parece ser um nome v√°lido de pessoa ou empresa (vers√£o simplificada)"""
        if not texto or len(texto) < 3:
            return False
        
        texto_limpo = texto.strip()
        
        # Rejeitar textos muito longos
        if len(texto_limpo) > 120:
            return False
        
        # Rejeitar se √© s√≥ n√∫meros, s√≠mbolos ou c√≥digo
        if re.match(r'^[\d\s\-\.\/\(\)]+$', texto_limpo):
            return False
        
        # Rejeitar palavras t√©cnicas muito espec√≠ficas
        palavras_rejeitadas = [
            'conhecimento', 'ativo', 'processo', 'vara', 'tribunal', 'custas',
            'c√≥digo', 'protocolo', 'certid√£o', 'cpf', 'cnpj', 'registro'
        ]
        
        # Verificar se cont√©m apenas palavras rejeitadas
        palavras_texto = texto_limpo.lower().split()
        if all(palavra in palavras_rejeitadas for palavra in palavras_texto if len(palavra) > 2):
            return False
        
        # Deve ter pelo menos uma letra
        if not re.search(r'[a-zA-Z√Ä-≈∏√†-√ø]', texto_limpo):
            return False
        
        # Deve ter pelo menos 2 palavras significativas (2+ caracteres)
        palavras_significativas = [p for p in texto_limpo.split() if len(p) >= 2]
        if len(palavras_significativas) < 1:  # Relaxado de 2 para 1
            return False
        
        # N√£o deve ter mais de 50% n√∫meros
        numeros = re.findall(r'\d', texto_limpo)
        if len(numeros) > len(texto_limpo) * 0.5:
            return False
        
        # APROVADO: Muito mais permissivo para capturar nomes reais
        return True
    
    def _obter_contexto_elemento(self, elemento) -> str:
        """Obt√©m contexto do elemento para determinar tipo de parte"""
        contexto = ""
        
        # Verificar elemento pai
        if elemento.parent:
            contexto += elemento.parent.get_text()
        
        # Verificar irm√£os anteriores e posteriores
        for sibling in elemento.previous_siblings:
            if hasattr(sibling, 'get_text'):
                contexto += sibling.get_text()
                
        for sibling in elemento.next_siblings:
            if hasattr(sibling, 'get_text'):
                contexto += sibling.get_text()
        
        return contexto.upper()
    
    def _determinar_tipo_parte_contexto(self, contexto: str) -> str:
        """Determina tipo de parte baseado no contexto"""
        if any(palavra in contexto for palavra in ['POLO ATIVO', 'REQUERENTE', 'AUTOR']):
            return 'polo_ativo'
        elif any(palavra in contexto for palavra in ['POLO PASSIVO', 'REQUERIDO', 'R√âU']):
            return 'polo_passivo'
        else:
            return 'outros'
    
    def _extrair_parte_da_linha_tabela(self, linha, tipo_parte: str) -> Optional[ParteEnvolvida]:
        """Extrai informa√ß√µes de parte de uma linha de tabela"""
        try:
            colunas = linha.find_all(['td', 'th'])
            if not colunas:
                return None
            
            # Primeira coluna geralmente √© o nome
            nome = colunas[0].get_text(strip=True)
            if not nome or nome.upper() in ['NOME', 'PARTE', 'SUJEITO']:
                return None
            
            # Tentar extrair outras informa√ß√µes das colunas seguintes
            documento = ""
            endereco = ""
            telefone = ""
            advogado = ""
            
            for i, coluna in enumerate(colunas[1:], 1):
                texto_coluna = coluna.get_text(strip=True)
                
                if re.search(r'\d{3}\.\d{3}\.\d{3}-\d{2}|\d{2}\.\d{3}\.\d{3}/\d{4}-\d{2}', texto_coluna):
                    documento = texto_coluna
                elif re.search(r'Rua|Av|Avenida|Quadra|Lote', texto_coluna, re.I):
                    endereco = texto_coluna
                elif re.search(r'\(\d{2}\)|^\d{2,}', texto_coluna):
                    telefone = texto_coluna
                elif re.search(r'OAB|Advogado', texto_coluna, re.I):
                    advogado = texto_coluna
            
            return ParteEnvolvida(
                nome=self._limpar_nome_parte(nome),
                tipo=tipo_parte.replace('_', ' ').title(),
                documento=documento,
                endereco=endereco,
                telefone=telefone,
                advogado=advogado
            )
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao extrair parte da linha: {e}")
            return None
    
    def _extrair_parte_do_elemento(self, elemento, tipo_parte: str) -> Optional[ParteEnvolvida]:
        """Extrai informa√ß√µes de parte de um elemento gen√©rico"""
        try:
            texto = elemento.get_text(strip=True)
            if not texto:
                return None
            
            # Dividir texto em linhas para an√°lise
            linhas = [linha.strip() for linha in texto.split('\n') if linha.strip()]
            
            nome = ""
            documento = ""
            endereco = ""
            telefone = ""
            advogado = ""
            
            for linha in linhas:
                if self._parece_nome_pessoa(linha) and not nome:
                    nome = linha
                elif re.search(r'\d{3}\.\d{3}\.\d{3}-\d{2}|\d{2}\.\d{3}\.\d{3}/\d{4}-\d{2}', linha):
                    documento = linha
                elif re.search(r'Rua|Av|Avenida|Quadra|Lote', linha, re.I):
                    endereco = linha
                elif re.search(r'\(\d{2}\)|^\d{2,}', linha):
                    telefone = linha
                elif re.search(r'OAB|Advogado', linha, re.I):
                    advogado = linha
            
            if nome:
                return ParteEnvolvida(
                    nome=self._limpar_nome_parte(nome),
                    tipo=tipo_parte.replace('_', ' ').title(),
                    documento=documento,
                    endereco=endereco,
                    telefone=telefone,
                    advogado=advogado
                )
            
            return None
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao extrair parte do elemento: {e}")
            return None
    
    def _extrair_partes_do_texto_secao(self, texto_secao: str, tipo_parte: str) -> List[ParteEnvolvida]:
        """Extrai partes de uma se√ß√£o de texto"""
        partes = []
        
        # Dividir por linhas ou separadores comuns
        linhas = re.split(r'\n|;|\|', texto_secao)
        
        for linha in linhas:
            linha = linha.strip()
            if self._parece_nome_pessoa(linha):
                parte = ParteEnvolvida(
                    nome=self._limpar_nome_parte(linha),
                    tipo=tipo_parte.replace('_', ' ').title(),
                    documento=self._extrair_documento_texto(linha),
                    endereco=self._extrair_endereco_texto(linha)
                )
                partes.append(parte)
        
        return partes
    
    def _extrair_documento_texto(self, texto: str) -> str:
        """Extrai documento (CPF/CNPJ) do texto"""
        match = re.search(r'\d{3}\.\d{3}\.\d{3}-\d{2}|\d{2}\.\d{3}\.\d{3}/\d{4}-\d{2}', texto)
        return match.group(0) if match else ""
    
    def _extrair_endereco_texto(self, texto: str) -> str:
        """Extrai endere√ßo do texto"""
        padroes_endereco = [
            r'(Rua|Av|Avenida|Quadra|Lote)[^,\n]+',
            r'(Endere√ßo[:\s]+[^,\n]+)',
        ]
        
        for padrao in padroes_endereco:
            match = re.search(padrao, texto, re.I)
            if match:
                return match.group(0).strip()
        
        return ""
    
    def _extrair_partes_do_fieldset(self, fieldset, tipo_polo: str) -> List[ParteEnvolvida]:
        """Extrai partes de um fieldset espec√≠fico - estrat√©gia melhorada"""
        partes = []
        nomes_unicos = set()  # Para evitar duplicatas
        
        try:
            # ESTRAT√âGIA CORRETA: Buscar APENAS por <span class="span1"> que cont√©m os nomes reais
            spans_nomes = fieldset.find_all('span', {'class': 'span1'})
            
            logger.info(f"üîç Fieldset {tipo_polo}: {len(spans_nomes)} spans com nomes encontrados")
            
            for span in spans_nomes:
                try:
                    nome_raw = span.get_text().strip()
                    
                    # Limpar nome
                    nome_limpo = self._limpar_nome_parte(nome_raw)
                    
                    # Verificar se √© v√°lido e √∫nico
                    if nome_limpo and nome_limpo not in nomes_unicos and len(nome_limpo) > 3:
                        # Valida√ß√£o adicional - deve ser um nome real
                        if self._parece_nome_valido(nome_limpo):
                            nomes_unicos.add(nome_limpo)
                            
                            # Extrair informa√ß√µes adicionais do contexto do fieldset
                            contexto = str(fieldset)
                            documento = self._extrair_documento(contexto)
                            endereco = self._extrair_endereco(contexto)
                            
                            parte = ParteEnvolvida(
                                nome=nome_limpo,
                                tipo=tipo_polo,
                                documento=documento,
                                endereco=endereco
                            )
                            
                            partes.append(parte)
                            logger.debug(f"  ‚úÖ Parte adicionada: {nome_limpo}")
                        else:
                            logger.debug(f"  ‚ùå Nome rejeitado pelo filtro: {nome_limpo}")
                    else:
                        if nome_limpo in nomes_unicos:
                            logger.debug(f"  ‚ùå Nome duplicado: {nome_limpo}")
                        else:
                            logger.debug(f"  ‚ùå Nome inv√°lido: {nome_limpo}")
                            
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Erro ao processar span: {e}")
                    continue
            
            # FALLBACK: Se n√£o encontrou spans, usar estrat√©gia anterior (mais restritiva)
            if not partes:
                logger.info(f"üîÑ Fallback: Usando extra√ß√£o por texto para {tipo_polo}")
                
                # Obter texto completo do fieldset, mas excluir divs de endere√ßo
                fieldset_copy = fieldset.__copy__()
                
                # Remover divs de endere√ßo
                for div_endereco in fieldset_copy.find_all('div', {'class': 'DivInvisivel'}):
                    div_endereco.decompose()
                
                # Remover fieldsets de endere√ßo
                for fieldset_endereco in fieldset_copy.find_all('fieldset', {'class': 'fieldsetEndereco'}):
                    fieldset_endereco.decompose()
                
                texto_fieldset = fieldset_copy.get_text()
                linhas = [linha.strip() for linha in texto_fieldset.split('\n') if linha.strip()]
                
                # Filtrar linhas que parecem nomes
                for linha in linhas:
                    # Pular labels e t√≠tulos
                    if any(palavra in linha.lower() for palavra in ['nome', 'polo', 'requerente', 'requerido', 'endere√ßo', 'telefone', 'cpf', 'cnpj']):
                        continue
                    
                    # Pular linhas muito curtas ou muito longas
                    if len(linha) < 5 or len(linha) > 100:
                        continue
                    
                    # Verificar se parece um nome v√°lido
                    if self._parece_nome_valido(linha):
                        nome_limpo = self._limpar_nome_parte(linha)
                        
                        if nome_limpo and nome_limpo not in nomes_unicos:
                            nomes_unicos.add(nome_limpo)
                            
                            contexto = str(fieldset)
                            documento = self._extrair_documento(contexto)
                            endereco = self._extrair_endereco(contexto)
                            
                            parte = ParteEnvolvida(
                                nome=nome_limpo,
                                tipo=tipo_polo,
                                documento=documento,
                                endereco=endereco
                            )
                            
                            partes.append(parte)
            
            logger.info(f"üìã Fieldset {tipo_polo}: {len(partes)} partes √∫nicas extra√≠das")
            return partes
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao extrair partes do fieldset: {e}")
            return []
    
    def _extrair_partes_do_texto(self, texto: str) -> List[ParteEnvolvida]:
        """Extrai partes do texto da p√°gina usando regex"""
        partes = []
        
        try:
            # Padr√µes para identificar partes
            padroes = [
                r'(?:Autor|AUTOR)[:\s]+([^\n\r\(]+)',
                r'(?:R√©u|R√âU)[:\s]+([^\n\r\(]+)',
                r'(?:Requerente|REQUERENTE)[:\s]+([^\n\r\(]+)',
                r'(?:Requerido|REQUERIDO)[:\s]+([^\n\r\(]+)',
                r'\(Polo\s+Ativo\)\s+([^\(\n\r]+)',
                r'\(Polo\s+Passivo\)\s+([^\(\n\r]+)'
            ]
            
            nomes_encontrados = set()
            
            for padrao in padroes:
                matches = re.finditer(padrao, texto, re.I)
                for match in matches:
                    nome = match.group(1).strip()
                    nome = re.sub(r'\s*\(.*?\)\s*', '', nome).strip()
                    nome = re.sub(r'\s*\-.*$', '', nome).strip()
                    
                    if nome and len(nome) > 3 and nome not in nomes_encontrados:
                        nomes_encontrados.add(nome)
                        nome_limpo = self._limpar_nome_parte(nome)
                        
                        # Determinar tipo baseado no padr√£o
                        if 'ativo' in match.group(0).lower() or 'autor' in match.group(0).lower():
                            tipo = 'Polo Ativo'
                        elif 'passivo' in match.group(0).lower() or 'r√©u' in match.group(0).lower():
                            tipo = 'Polo Passivo'
                        else:
                            tipo = 'Parte'
                        
                        parte = ParteEnvolvida(
                            nome=nome_limpo,
                            tipo=tipo
                        )
                        partes.append(parte)
            
            return partes
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao extrair partes do texto: {e}")
            return []
    
    def _limpar_nome_parte(self, nome_completo: str) -> str:
        """Limpa o nome da parte removendo informa√ß√µes extras"""
        try:
            # Remover tags HTML
            nome_limpo = re.sub(r'<[^>]+>', '', nome_completo)
            
            # Remover palavras-chave
            palavras_remover = ['citado', 'r√©u', 'autor', 'requerente', 'requerido']
            for palavra in palavras_remover:
                nome_limpo = re.sub(rf'\b{palavra}\b', '', nome_limpo, flags=re.I)
                nome_limpo = re.sub(rf'{palavra}', '', nome_limpo, flags=re.I)
            
            # Limpar espa√ßos e caracteres especiais
            nome_limpo = re.sub(r'\s+', ' ', nome_limpo).strip()
            nome_limpo = re.sub(r'[^\w\s\.\-]', '', nome_limpo)
            nome_limpo = re.sub(r'\s+', ' ', nome_limpo).strip()
            
            return nome_limpo
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao limpar nome: {e}")
            return nome_completo
    
    def _extrair_documento(self, texto: str) -> str:
        """Extrai CPF/CNPJ do texto"""
        try:
            # Padr√£o para CPF/CNPJ
            match = re.search(r'(?:CPF|CNPJ)[\s:]*(\d{3}\.?\d{3}\.?\d{3}-?\d{2}|\d{2}\.?\d{3}\.?\d{3}/?\d{4}-?\d{2})', texto, re.I)
            return match.group(1) if match else ""
        except:
            return ""
    
    def _extrair_endereco(self, texto: str) -> str:
        """Extrai endere√ßo do texto, removendo HTML"""
        try:
            # Primeiro, limpar HTML tags e onclick
            texto_limpo = re.sub(r'<[^>]*onclick[^>]*>', '', texto)
            texto_limpo = re.sub(r'<[^>]*>', '', texto_limpo)
            texto_limpo = re.sub(r'\\"[^"]*\\"', '', texto_limpo)
            texto_limpo = re.sub(r"\\['\"]", '', texto_limpo)
            
            # Padr√£o para endere√ßo
            match = re.search(r'(?:Endere√ßo|endere√ßo)[\s:]*([^\n\r]+)', texto_limpo, re.I)
            endereco = match.group(1).strip() if match else ""
            
            # Limpar ainda mais o endere√ßo
            endereco = re.sub(r'type=["\'][^"\']*["\']', '', endereco)
            endereco = re.sub(r'onclick=["\'][^"\']*["\']', '', endereco)
            endereco = re.sub(r'title=["\'][^"\']*["\']', '', endereco)
            endereco = endereco.strip()
            
            return endereco if len(endereco) > 5 else ""
        except:
            return ""

# Inst√¢ncia global do gerenciador de processo
processo_manager = ProcessoManager()